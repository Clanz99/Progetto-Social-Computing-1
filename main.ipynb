{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PROGETTO 1 SOCIAL COMPUTING\n",
    "\n",
    "## 1. DOWNLOAD FOLLOWER E FOLLOWING\n",
    "Scaricate utenti followers (api.followers) e utenti following (api.friends) di\n",
    "questi cinque account (i dati numerici potrebbero subire minime variazioni):\n",
    "- @mizzaro - 156 Follower - 331 Following\n",
    "- @damiano10 - 785 Follower - 836 Following\n",
    "- @Miccighel_ - 331 Follower - 211 Following\n",
    "- @eglu81 - 540 Follower - 621 Following\n",
    "- @KevinRoitero - 103 Follower - 256 Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "if(api.verify_credentials):\n",
    "    print('Authentication completed succesfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "data_folder = \"data\"\n",
    "underline = \"\\033[4m\"\n",
    "fail = \"\\033[91m\"\n",
    "bold = \"\\033[1m\"\n",
    "endc = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def serialize_json(folder, filename, data):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    with open(f\"{folder}/{filename}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Data serialized to path: {folder}/{filename}\")\n",
    "\n",
    "    \n",
    "def read_json(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Data read from path: {path}\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found at path: {path}\")\n",
    "        return {}\n",
    "\n",
    "def getData(account):\n",
    "    print(f\"Getting ID-FollowersQuantity-FriendsQuantity of: {account}\")\n",
    "    json_data = api.get_user(account)._json\n",
    "    data = []\n",
    "    data.append(json_data['id_str'])\n",
    "    data.append(json_data['followers_count'])\n",
    "    data.append(json_data['friends_count'])\n",
    "    data.append(json_data['protected'])\n",
    "    return data\n",
    "\n",
    "\n",
    "def getFollowers(account, ids, quantity, path, save=True):\n",
    "    for item in tweepy.Cursor(\n",
    "            api.followers,\n",
    "            id=account,\n",
    "            skip_status=True,\n",
    "            include_user_entities=False\n",
    "    ).items(quantity):\n",
    "\n",
    "        json_data = item._json\n",
    "        found_follower = json_data[\"id_str\"]\n",
    "        \n",
    "        if found_follower not in ids:\n",
    "            ids.append(found_follower)\n",
    "        print(f\"Processing Follower #{len(ids)} of account: {account}\")\n",
    "    \n",
    "    if(save==True): \n",
    "        serialize_json(data_folder, path, ids)\n",
    "   \n",
    "    print(f\"Processing Followers Completed\")\n",
    "    \n",
    "\n",
    "def getFriends(account, ids, quantity, path, save=True):\n",
    "    \n",
    "    for item in tweepy.Cursor(\n",
    "            api.friends,\n",
    "            id=account,\n",
    "            skip_status=True,\n",
    "            include_user_entities=False\n",
    "    ).items(quantity):\n",
    "\n",
    "        json_data = item._json\n",
    "        found_follower = json_data[\"id_str\"]\n",
    "        \n",
    "        if found_follower not in ids:\n",
    "            ids.append(found_follower)\n",
    "        print(f\"Processing Friend #{len(ids)} of account: {account}\")\n",
    "    \n",
    "    if(save==True): \n",
    "        serialize_json(data_folder, path, ids)\n",
    "        \n",
    "    print(f\"Processing Friends Completed\")\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Setup Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ACCOUNT DA ANALIZZARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_to_analyze = [\"mizzaro\", \"damiano10\", \"Miccighel_\", \"eglu81\", \"KevinRoitero\"]\n",
    "account_to_analyze_id = []\n",
    "account_to_analyze_followers_quantity = []\n",
    "account_to_analyze_friends_quantity = []\n",
    "\n",
    "for x in account_to_analyze:\n",
    "    data = getData(x)\n",
    "    account_to_analyze_id.append(data[0])\n",
    "    account_to_analyze_followers_quantity.append(data[1])\n",
    "    account_to_analyze_friends_quantity.append(data[2])\n",
    "    \n",
    "print(f\"Account to Analyze: {account_to_analyze}\")\n",
    "print(f\"Account to Analyze ID: {account_to_analyze_id}\")\n",
    "print(f\"Account to Analyze Followers Quantity: {account_to_analyze_followers_quantity}\")\n",
    "print(f\"Account to Analyze Friends Quantity: {account_to_analyze_friends_quantity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SALVATAGGIO ID FOLLOWERS E FRIENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mizzaro\n",
    "account_id = account_to_analyze_id[0]\n",
    "followers_quantity = account_to_analyze_followers_quantity[0]\n",
    "friends_quantity = account_to_analyze_friends_quantity[0]\n",
    "account_ids = []\n",
    "getFollowers(account_id, account_ids, followers_quantity, account_to_analyze[0]+\"FollowerIDs.json\")\n",
    "account_ids = []\n",
    "getFriends(account_id, account_ids, friends_quantity, account_to_analyze[0]+\"FriendIDs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#damiano10\n",
    "account_id = account_to_analyze_id[1]\n",
    "followers_quantity = account_to_analyze_followers_quantity[1]\n",
    "friends_quantity = account_to_analyze_friends_quantity[1]\n",
    "account_ids = []\n",
    "getFollowers(account_id, account_ids, followers_quantity, account_to_analyze[1]+\"FollowerIDs.json\")\n",
    "account_ids = []\n",
    "getFriends(account_id, account_ids, friends_quantity, account_to_analyze[1]+\"FriendIDs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Miccighel_\n",
    "account_id = account_to_analyze_id[2]\n",
    "followers_quantity = account_to_analyze_followers_quantity[2]\n",
    "friends_quantity = account_to_analyze_friends_quantity[2]\n",
    "account_ids = []\n",
    "getFollowers(account_id, account_ids, followers_quantity, account_to_analyze[2]+\"FollowerIDs.json\")\n",
    "account_ids = []\n",
    "getFriends(account_id, account_ids, friends_quantity, account_to_analyze[2]+\"FriendIDs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eglu81\n",
    "account_id = account_to_analyze_id[3]\n",
    "followers_quantity = account_to_analyze_followers_quantity[3]\n",
    "friends_quantity = account_to_analyze_friends_quantity[3]\n",
    "account_ids = []\n",
    "getFollowers(account_id, account_ids, followers_quantity, account_to_analyze[3]+\"FollowerIDs.json\")\n",
    "account_ids = []\n",
    "getFriends(account_id, account_ids, friends_quantity, account_to_analyze[3]+\"FriendIDs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KevinRoitero\n",
    "account_id = account_to_analyze_id[4]\n",
    "followers_quantity = account_to_analyze_followers_quantity[4]\n",
    "friends_quantity = account_to_analyze_friends_quantity[4]\n",
    "account_ids = []\n",
    "getFollowers(account_id, account_ids, followers_quantity, account_to_analyze[4]+\"FollowerIDs.json\")\n",
    "account_ids = []\n",
    "getFriends(account_id, account_ids, friends_quantity, account_to_analyze[4]+\"FriendIDs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versione con un unico ciclo da inserire nella relazione \n",
    "for x in range(len(account_to_analyze)):\n",
    "    account_id = account_to_analyze_id[x]\n",
    "    followers_quantity = account_to_analyze_followers_quantity[x]\n",
    "    friends_quantity = account_to_analyze_friends_quantity[x]\n",
    "    account_ids = []\n",
    "    getFollowers(account_id, account_ids, followers_quantity, account_to_analyze[x]+\"FollowerIDs.json\")\n",
    "    account_ids = []\n",
    "    getFriends(account_id, account_ids, friends_quantity, account_to_analyze[x]+\"FriendIDs.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. CINQUE FOLLOWERS RANDOM\n",
    "IMPORTANTE!!! Nella relazione scrivere anche della possibilità di usare random.sample()\n",
    "\n",
    "Scegliete 5 utenti followers a caso tra quelli di ciascuno dei cinque account e scaricate ulteriori 10 utenti followers (followers dei followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def randomizeFollower(read_path, ids):\n",
    "    print(f\"Getting Randomized Followers from {read_path}\")\n",
    "    data_account = read_json(read_path)\n",
    "    for x in range(5):\n",
    "        randomizeFollowerRec(data_account, ids)\n",
    "\n",
    "def randomizeFollowerRec(data_ids, ids):\n",
    "    rand = random.choice(data_ids)\n",
    "    user_data = getData(rand)\n",
    "    if(rand in ids):\n",
    "        randomizeFollowerRec(data_ids, ids)\n",
    "    elif(user_data[3]):\n",
    "        randomizeFollowerRec(data_ids, ids)\n",
    "    elif(user_data[1] <=10):\n",
    "        randomizeFollowerRec(data_ids, ids)\n",
    "    else:\n",
    "        ids.append(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizzazione di 25 follower, 5 per ogni account iniziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "follower_ids = []\n",
    "for x in account_to_analyze:\n",
    "    randomizeFollower(\"data/\"+x+\"FollowerIDs.json\", follower_ids)\n",
    "\n",
    "print(f\"{len(follower_ids)} Followers of Followers: {follower_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio degli ID di 10 Follower dei Follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_ids = []\n",
    "\n",
    "for x in follower_ids:\n",
    "    getFollowers(x, account_ids, 10, \"FollowerOfFollowerIDs.json\", False)\n",
    "\n",
    "serialize_json(data_folder, \"FollowerOfFollowerIDs.json\", account_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CINQUE FRIENDS RANDOM\n",
    "\n",
    "Scegliete 5 utenti following a caso tra quelli di ciascuno dei cinque account e\n",
    "scaricate ulteriori 10 utenti following (following dei following)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizeFriend(read_path, ids):\n",
    "    print(f\"Getting Randomized Friends from {read_path}\")\n",
    "    data_account = read_json(read_path)\n",
    "    for x in range(5):\n",
    "        randomizeFriendRec(data_account, ids)\n",
    "\n",
    "def randomizeFriendRec(data_ids, ids):\n",
    "    rand = random.choice(data_ids)\n",
    "    user_data = getData(rand)\n",
    "    if(rand in ids):\n",
    "        randomizeFriendRec(data_ids, ids)\n",
    "    elif(user_data[3]):\n",
    "        randomizeFriendRec(data_ids, ids)\n",
    "    elif(user_data[2] <=10):\n",
    "        randomizeFriendRec(data_ids, ids)\n",
    "    else:\n",
    "        ids.append(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizzazione di 25 friend, 5 per ogni account iniziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_ids = []\n",
    "#randomizzazione di 25 friends totali\n",
    "for x in account_to_analyze:\n",
    "    randomizeFriend(\"data/\"+x+\"FriendIDs.json\", friend_ids)\n",
    "\n",
    "print(f\"{len(friend_ids)} Friends of Friends: {friend_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio degli ID di 10 Friend dei Friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_ids = []\n",
    "\n",
    "for x in friend_ids:\n",
    "    getFriends(x, account_ids, 10, \"FriendOfFriendIDs.json\", False)\n",
    "\n",
    "serialize_json(data_folder, \"FriendOfFriendIDs.json\", account_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvataggio di tutti gli ID in un unico file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonAppend(json1, json2):\n",
    "    json = json1 + json2\n",
    "    json = list(set(json))\n",
    "    return json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "# aggiunta id account iniziali\n",
    "for x in account_to_analyze_id:\n",
    "    all_ids.append(x)\n",
    "print(f\"Total Account IDs: {len(all_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggiunta id followers of followers e friends of friends\n",
    "all_ids = jsonAppend(all_ids, read_json(\"data/FriendOfFriendIDs.json\"))\n",
    "all_ids = jsonAppend(all_ids, read_json(\"data/FollowerOfFollowerIDs.json\"))\n",
    "\n",
    "print(f\"Total Account IDs: {len(all_ids)}\")\n",
    "\n",
    "# aggiunta id di followers e friends degli account iniziali\n",
    "for x in account_to_analyze:\n",
    "    all_ids = jsonAppend(all_ids, read_json(\"data/\"+x+\"FollowerIDs.json\"))\n",
    "    all_ids = jsonAppend(all_ids, read_json(\"data/\"+x+\"FriendIDs.json\"))\n",
    "    print(f\"Total Account IDs: {len(all_ids)}\")\n",
    "\n",
    "# salvataggio di tutti gli id\n",
    "serialize_json(data_folder, \"AllIDs.json\", all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DETTAGLI PROFILI\n",
    "Scaricare i dettagli del profilo di tutti gli utenti recuperati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFrameAppend(path, data):\n",
    "    dataframe = createDataFrame(data)\n",
    "    dataframe.to_csv(path, mode='a', header=False, index=False)\n",
    "    \n",
    "def createDataFrame(data):\n",
    "    json_normalized = pd.json_normalize(data)\n",
    "    dataframe = pd.DataFrame(json_normalized)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 DOWNLOAD DATI DI OGNI NODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/all_nodes.csv\"\n",
    "all_ids = read_json(\"data/AllIDs.json\")\n",
    "all_user_data = []\n",
    "\n",
    "for x in all_ids:\n",
    "    print(f\"Processing data of account: {x}\")\n",
    "    try:\n",
    "        user_data = api.get_user(x)._json\n",
    "        all_user_data.append(user_data)\n",
    "    except:\n",
    "        print(f\"{fail}{bold}Error with account: {x}\")\n",
    "\n",
    "createDataFrame(all_user_data).to_csv(path, index=False)\n",
    "print(f\"Processing Completed and Data Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Processing data of account: {all_ids[0]}\")\n",
    "#createDataFrame(api.get_user(all_ids[0], include_user_entities=False)._json).to_csv(path, index=False)\n",
    "#for x in all_ids[1:]:\n",
    "#    print(f\"Processing data of account: {x}\")\n",
    "#    dataFrameAppend(path, api.get_user(x, include_user_entities=False)._json)\n",
    "\n",
    "#print(f\"Processing Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 SALVATAGGIO ARCHI (friendship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFriendship(source, target, path):\n",
    "    print(f\"Processing Friendship Between {source} and {target}\")\n",
    "    try:\n",
    "        friendship = api.show_friendship(source_id=source, target_id=target)  \n",
    "        if friendship[0].following == True :\n",
    "            data = {}\n",
    "            data['source'] = source\n",
    "            data['target'] = target\n",
    "            dataFrameAppend(path, data)\n",
    "            print(f\"{source} follows {target}\")\n",
    "        if friendship[0].followed_by == True :\n",
    "            data = {}\n",
    "            data['source'] = target\n",
    "            data['target'] = source\n",
    "            dataFrameAppend(path, data)  \n",
    "            print(f\"{target} follows {source}\")\n",
    "    except:\n",
    "        print(f\"{fail}{bold}Error with account: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = read_json(\"data/AllIDs.json\")\n",
    "path = \"data/all_edges.csv\"\n",
    "columns = [\"source\", \"target\"]\n",
    "pd.DataFrame(columns=columns).to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mizzaro\n",
    "for x in all_nodes:\n",
    "    checkFriendship(account_to_analyze_id[0], x, path)\n",
    "print(f\"Processing Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#damiano10\n",
    "for x in all_nodes:\n",
    "    checkFriendship(account_to_analyze_id[1], x, path)\n",
    "print(f\"Processing Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Miccighel_\n",
    "for x in all_nodes:\n",
    "    checkFriendship(account_to_analyze_id[2], x, path)\n",
    "print(f\"Processing Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eglu81\n",
    "for x in all_nodes:\n",
    "    checkFriendship(account_to_analyze_id[3], x, path)\n",
    "print(f\"Processing Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KevinRoitero\n",
    "for x in all_nodes:\n",
    "    checkFriendship(account_to_analyze_id[4], x, path)\n",
    "print(f\"Processing Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# versione con un ciclo\n",
    "for x in all_nodes:\n",
    "    checkFriendship(account_to_analyze_id[0], x, path)\n",
    "    checkFriendship(account_to_analyze_id[1], x, path)\n",
    "    checkFriendship(account_to_analyze_id[2], x, path)\n",
    "    checkFriendship(account_to_analyze_id[3], x, path)\n",
    "    checkFriendship(account_to_analyze_id[4], x, path)\n",
    "\n",
    "# versione alternativa con due cicli\n",
    "for x in account_to_analyze_id:\n",
    "    for y in all_nodes:\n",
    "        checkFriendship(x, y, path)\n",
    "\n",
    "#ACCOUNT DA ELIMINARE CHE NON ESISTE PIù \"1319272146963673089\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminazione di eventuali righe duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/all_edges.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.drop_duplicates()\n",
    "df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/all_edges.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.drop(0, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. COSTRUIRE RETE SOCIALE\n",
    "Costruite la rete sociale (grafo):\n",
    "- Inserite l’id di ciascun utente come identificatore del nodo\n",
    "- Ogni arco rappresenta una relazione follows tra due utenti\n",
    "- Inserite i dettagli del profilo di ciascun utente come attributi del nodo\n",
    "- Inserite i membri del vostro gruppo come attributi del grafo\n",
    "- Per ogni nodo, aggiungete un attributo con il numero di follower individuati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(nodes_path, edges_path):\n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    graph = nx.DiGraph()\n",
    "    for index, row in nodes_df.iterrows():\n",
    "        graph.add_node(row['id'])\n",
    "    for index, row in edges_df.iterrows():\n",
    "        #print(row['source'].dtype)\n",
    "        graph.add_edge(row['source'], row['target'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph2(nodes_path, edges_path):\n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    graph = nx.Graph()\n",
    "    for index, row in nodes_df.iterrows():\n",
    "        graph.add_node(row['id'])\n",
    "    for index, row in edges_df.iterrows():\n",
    "        #print(row['source'].dtype)\n",
    "        graph.add_edge(row['source'], row['target'])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = createGraph(\"data/all_nodes.csv\", \"data/all_edges.csv\")\n",
    "nx.write_gpickle(graph, \"data/graph.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = createGraph(\"data/all_nodes.csv\", \"data/all_edges.csv\")\n",
    "nx.write_gpickle(graph2, \"data/graph2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "graph = nx.read_gpickle(\"data/graph.pkl\")\n",
    "rcParams['figure.figsize'] = 10, 10\n",
    "nx.draw_networkx(\n",
    "    graph,\n",
    "    pos = nx.spring_layout(graph),\n",
    "    node_color = '#A0CBE2',\n",
    "    width = 2,\n",
    "    edge_cmap = plt.cm.Blues,\n",
    "    with_labels = True\n",
    ")\n",
    "plt.savefig(\"data/graph.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "Producete una visualizzazione interattiva del grafo usando pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "graph = nx.read_gpickle(\"data/graph.pkl\")\n",
    "print(graph.number_of_nodes())\n",
    "print(graph.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntGraph = Network(\n",
    "    height=\"100%\", \n",
    "    width=\"100%\", \n",
    "    bgcolor=\"#222222\", \n",
    "    font_color=\"white\",\n",
    "    heading=\"MiccighelGraph\"\n",
    ")\n",
    "ntGraph.barnes_hut()\n",
    "ntGraph.from_nx(graph)\n",
    "neighbor_map = nt.get_adj_list()\n",
    "for node in nt.nodes:\n",
    "    node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "ntGraph.show(\"graphToPlot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\n",
    "Verificate se il grafo:\n",
    "- è connesso (is_connected)\n",
    "- è bipartito (is_bipartite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\n",
    "Misurate le seguenti distanze sul grafo:\n",
    "- Centro (center)\n",
    "- Diametro (diameter)\n",
    "- Raggio (radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.\n",
    "Calcolate le seguenti misure di centralità sul grafo:\n",
    "- Betweenness centrality (betweenness_centrality)\n",
    "- Closeness centrality (closeness_centrality)\n",
    "- Degree centrality (degree_centrality)\n",
    "- In-degree centrality (in_degree_centrality)\n",
    "- Out-degree centrality (out_degree_centrality)\n",
    "- Page Rank (pagerank)\n",
    "- HITS (hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.\n",
    "Generate il sottografo indotto dal nodo damiano10 (ego_graph) e calcolate:\n",
    "- Cricca massima (max_clique)\n",
    "- Dimensione della cricca massima (large_clique_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.\n",
    "Calcolate la copertura minima degli archi (min_edge_cover) del grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.\n",
    "Calcolate i seguenti coefficienti per stimare la “small-world-ness” del grafo:\n",
    "- Coefficiente omega (omega)\n",
    "- Coefficiente sigma (sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.\n",
    "Calcolare la correlazione di Pearson Rho e di Kendall Tau fra le misure di centralità;\n",
    "riportare il risultato in due tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
